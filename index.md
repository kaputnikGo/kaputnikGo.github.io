## Audio Tracker demo

_(using **Alphonso SDK** (third) example of capturing spoken phonetic alphabet)_

### Intro
The question of "is my device listening to me?" has been asked many times over the past few years. To help determine an answer to this question a demonstration scenario will be examined here detailing the use of an Android mobile phone and a game app downloaded for free from Google Play.

The app chosen has the RECORD_AUDIO permission (as listed on the store page) and is known to contain the Alphonso SDK. This SDK is used for Audio Content Recognition (**ACR**) and cross device tracking (**XDT**), a technique that attempts to derive and match unique aspects (fingerprint) of a given audio sample with a database of known fingerprints. 

### Method
The following investigation will demonstrate that the Alphonso SDK included in the game app records audio which it then packages into 64kb files suitable for uploading to servers. After installing the app, approving the permissions and then running it for the first time, the phonetic alphabet was spoken out loud in the vicinity of the mobile device. A ten second portion of this spoken alphabet is captured by the SDK using its default settings and subdivided into five 64kb files of raw audio data. Importing the five raw audio files into Audacity as Signed 16 bit PCM, little-endian, mono, 8000Hz allows the audio to be played back legibly.

### XDT
what is it... and why

### ACR
Audio Content Recognition is a system that generates an identifiable and simple "fingerprint" of a complex audio signal. A simplified example is in the way the Shazaam app listens to a song that is playing and can then identify the title and artist. To do this, the company offering the service creates a database of audio fingerprints generated by processing audio files through a particular algorithm. This algorithm creates a fingerprint based upon key features of the audio as determined by a spectrogram. 

![Shazaam audio spectrum fingerprint](/images/shazaam-audio-spectrum.jpg)

The left side of the above image shows the initial spectrogram of the audio as a representation of frequencies over time. The right side shows an example of key features being identified, here it is the intensity of a given frequency. From this a small section can then be indexed to provide a hash which can be stored in a database and queried.

Following a similar methodology, several ACR companies have created SDKs that are embedded within smart phone apps for the purpose of tracking what television shows and adverts are watched. The recordings usually last a few seconds (5 - 15 secs) and are processed on the device to generate a "finger print" of the audio. This fingerprint is then sent via a network connection to servers for querying. Most of these companies provide analytics to their clients so that they can assess what adverts are being seen and by whom. 

Expanding on this initial purpose, several companies are also using this ACR technique to record and determine what other sounds are present, especially in the background. One example is the La Liga Soccer app that is triggered by GPS location and records audio to determine whether the device is in the vicinity of an unauthorised broadcast of a soccer match - [Engadget La Liga app article](https://www.engadget.com/2018/06/13/spanish-soccer-app-la-liga-spying-pirate-broadcast/).

Another future trend can be found in a Facebook patent application that seeks to record and fingerprint background, ambient sounds to provide a context for devices and their usage - [Fastcompany Facebook ambient audio patent article](https://www.fastcompany.com/90178158/facebook-downplays-ambient-audio-tech-that-can-eavesdrop-on-you). This article also discusses other uses of this technique by companies such as Alphonso and Cambridge Analytica.

### APK Analysis
A page describing how an Android app's APK can be analysed is found on the [Exodus Privacy website](https://exodus-privacy.eu.org/en/post/exodus_static_analysis/).

In this particular investigation the Android game app is downloaded to a specific device used for mitmproxy use as well as on a computer via download using Raccoon and static analysis using jadx-gui.

![Victoria Aztec game screen](/images/VictoriaAztec_game.jpg)

Link to Google Play store game app:
[Victoria Aztec Hidden Object ](https://play.google.com/store/apps/details?id=com.fgl.adrianmarik.victoriaaztecsfree)

Google Play app store listing Alphonso SDK integration statement:
```markdown
This app is integrated with Alphonso software. Subject to your permission, 
the Alphonso software receives short duration audio samples from the 
microphone on your device. The audio samples never leave your device, 
but are irreversibly encoded (hashed) into digital "fingerprints." The 
fingerprints are compared off-device to commercial content (e.g., TV, 
OTT programming, ads music etc.). If a match is found, then appropriate 
recommendation for content or ads may be delivered to your mobile device. 
The Alphonso software only matches against known audio content and does 
not recognize or understand human conversations or other sounds.
```

![VictoriaAztec opt out screen](/images/VictoriaAztec_optout.jpg)

The Alphonso SDK in the app provides a link to the privacy policy of the game developer on its opt-out screen : [Molu Apps Privacy Policy](http://moluapps.com/Privacy_Policy.html).

Permissions requested by the app at install are shown to the user, as well as a brief reasoning:
```markdown
"This app uses audio to detect TV ads and content and shows appropriate mobile ads"
"android.permission.RECORD_AUDIO"
"android.permission.ACCESS_COARSE_LOCATION"
```

Knowing that this app will use the record audio function at some point not related to the gameplay, the next step is to try and determine when that might occur. Recording audio on an Android phone is a function that does not use a large amount of battery power or CPU processing cycles nor storage if only a few files are kept and constantly written over with fresh recordings. However, recording _useful_ audio on an Android device is problematic especially when the intent is to do some sort of processing to that audio to determine its useful characteristics. In this case, the specific processing is to try an identify what that audio consists of by using methods such as those discussed above, in the ACR section. The specific characteristics the SDK is interested in are derived from adverts and programmes and can be assumed to consist of either music, talking or even abstract sounds.

One of the first methods to reduce the amount of possible useless recordings, is to restrict when the SDK performs the reocrd audio method. As we are dealing with a cross device tracking SDK that triggers adverts the first check can be a device based query as to whether or not the device is actively being used. To help with this the PilferShush Jammer app, which contains a background services scanner, is used to list any services a particular app has that can run in the background. The service in this case is called **tv.alphonso.service.AlphonsoService** :

![Alphonso service detect](/images/Alphonso-service-detect.jpg)

The AlphonsoService calls sets various parameters including "deviceId", "androidId", "adId", "uuId" and a "PrimeTimeArray". 
```markdown
    public void initializePrimeTimeArray() {
        this.mPrimeTimeArray = new PrimeTime[5];
        this.mPrimeTimeArray[0] = new PrimeTime();
        this.mPrimeTimeArray[1] = new PrimeTime();
        this.mPrimeTimeArray[2] = new PrimeTime();
        this.mPrimeTimeArray[3] = new PrimeTime();
        this.mPrimeTimeArray[4] = new PrimeTime();
        this.mPrimeTimeArray[0].asFSMBeginEvent = 47;
        this.mPrimeTimeArray[0].asFSMEndEvent = 48;
        this.mPrimeTimeArray[1].asFSMBeginEvent = 49;
        this.mPrimeTimeArray[1].asFSMEndEvent = 50;
        this.mPrimeTimeArray[2].asFSMBeginEvent = 51;
        this.mPrimeTimeArray[2].asFSMEndEvent = 52;
        this.mPrimeTimeArray[3].asFSMBeginEvent = 53;
        this.mPrimeTimeArray[3].asFSMEndEvent = 54;
        this.mPrimeTimeArray[4].asFSMBeginEvent = 55;
        this.mPrimeTimeArray[4].asFSMEndEvent = 56;
    }
```

The primeTimeArray is created and set by tv.alphonso.service.PrimeTime which determines when to begin and end any audio captures. 
```markdown
public PrimeTime() {
    this.begin = "";
    this.end = "";
    this.captureCount = -1;
    this.captureScenarioSleepInterval = -1;
    this.captureScenarioSleepIntervalMax = -1;
    this.captureScenarioSleepIntervalLivetv = -1;
    this.captureScenarioSleepIntervalInhibiterIncrement = -1.0d;
}
```

It also calls tv.alphonso.service.LocationService which periodically reports the device location to a server.
```markdown    
  public void sendLocationUpdate(Location location) {
        Bundle params = new Bundle();
        params.putParcelable("location", location);
        if (this.mAlphonsoClient != null) {
            Message msg = this.mAlphonsoClient.mHandler.obtainMessage();
            msg.what = 3;
            msg.setData(params);
            if (debug) {
                Log.d(TAG, "Sending Location Update to AlphonsoClient.");
            }
            this.mAlphonsoClient.mHandler.sendMessage(msg);
        }
        if (this.mProvClient != null) {
            this.mProvClient.processLocationUpdate();
        }
    }
```

Location services are also used to determine whether the device is stationary, which can be a good indication that the user is sitting down and looking at the screen.

```markdown
tv.alphonso.utils.Utils (edit)
  locBundle.put("latitude", Double.valueOf(loc.getLatitude()));
  locBundle.put("longitude", Double.valueOf(loc.getLongitude()));
  locBundle.put("altitude", Double.valueOf(loc.getAltitude()))
  locBundle.put("speed", Float.valueOf(loc.getSpeed()));
  locBundle.put("bearing", Float.valueOf(loc.getBearing()));
  locBundle.put("accuracy", Float.valueOf(loc.getAccuracy()));
  
  getTMCountryCode(cxt);
  tm.getNetworkCountryIso(); 
```

The primetime settings have defaults that are set in tv.alphonso.utils.PreferencesManager.  :
```markdown  
  public static final String ACS_EVENING_PRIME_TIME_BEGIN_DEFAULT = "19:00";
  public static final String ACS_EVENING_PRIME_TIME_END_DEFAULT = "22:00";
  public static final String ACS_MORNING_PRIME_TIME_BEGIN_DEFAULT = "06:00";
  public static final String ACS_MORNING_PRIME_TIME_END_DEFAULT = "09:00";
```

So from here we can assume that the app has specific times and device attitudes that it will allow it to commence the audio capture process.


```markdown
alphonso.xml (edit)

<map>
  <float name="location_accuracy" value="5.3096943" />
  <string name="server_domain">http://tkacr197.alphonso.tv</string>
  <boolean name="audio_file_upload_flag" value="false" />
  <int name="capture_count" value="3" />
  <string name="acr_db_filename">acr.a.2.1.4.db.zero.mp3</string>
  <boolean name="capture_power_optimization_mode" value="true" />
  <int name="acr_shift" value="0" />
  <long name="capture_duration_ms" value="4000" />
  <long name="capture_scenario_sleep_interval" value="8" />
  <string name="acr_db_file_dir">/data/user/0/com.fgl.adrianmarik.victoriaaztecsfree/files</string>
  <long name="capture_scenario_sleep_interval_livetv_match" value="60" />
  <int name="capture_prebuffer_size" value="0" />
  <int name="db_max_records" value="1000" />
  <string name="acr_db_file_abs_path">/data/user/0/com.fgl.adrianmarik.victoriaaztecsfree/files/acr.a.2.1.4.db.zero.mp3</string>
  <boolean name="limit_ad_tracking_flag" value="false" />
  <string name="server_port">4432</string>
  <long name="capture_scenario_sleep_interval_max" value="160" />
  <long name="location_poll_interval" value="15" />
  <float name="location_speed" value="0.09888778" />
</map>

```

```markdown
tv.alphonso.audiorecorderservice.AudioRecorder (edit)
  
  private static final int RECORDER_AUDIO_ENCODING = 2;
  private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
  private static final int RECORDER_CHANNELS = 16;
  private static final int RECORDER_SAMPLERATE_44100 = 44100;
  private static final int RECORDER_SAMPLERATE_8000 = 8000;
  private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;

```

```markdown
tv.alphonso.alphonsoclient.AlphonsoClient (edit)
 
  if (args.getBoolean("audio_file_upload")) {
    params.put("filename", 
               getAudioFileUploadFilename(this.mDevId, args.getString("start_time"), 
               args.getString("acr_type"), 
               args.getString("result_suffix")));
  }
  
  public String getAudioFileUploadFilename(String deviceId, String startTime, String acrType, String resultSuffix) {
        StringBuffer filename = new StringBuffer();
        filename.append("android");
        filename.append("-");
        filename.append(deviceId);
        filename.append("-");
        filename.append(this.mAlphonsoUid);
        filename.append("-");
        filename.append(startTime);
        filename.append("-");
        filename.append(acrType);
        filename.append("-");
        filename.append(resultSuffix);
        filename.append(".audio.raw");
        return filename.toString();
    }
```

```markdown
tv.alphonso.audiocaptureservice.LocalACR (edit)

  protected String[] mLocalAudioMatchingToken = new String[]{"LocalACR1", "LocalACR2", "LocalACR3", "LocalACR4", "LocalACR5"};

```


### Images

![SDK audio file tree](/images/alphonsoSDK-audio_filetree.jpg)

![Completed audio join file](/images/Screenshot_3-step-join-speed-redux.png)

